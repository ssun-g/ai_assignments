{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34baf400-065b-4c4a-a898-1ddedd11049a",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03de0f7-2489-436a-8596-a906fd2ce3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.onnx\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import onnx\n",
    "import onnxoptimizer\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import CalibrationDataReader, quantize_static, QuantType, QuantFormat\n",
    "from onnxsim import simplify\n",
    "\n",
    "from utils.model import ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c4acf-7aae-45af-9399-d381c8528ea7",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6569713-0145-4550-beb1-6b13b943bbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {'seed': 42,\n",
    "       'bs': 1,\n",
    "       'imgsz': (64, 64),  # height, width\n",
    "       'mean': (0.485, 0.456, 0.406),\n",
    "       'std': (0.229, 0.224, 0.225),\n",
    "       'n_cls': 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b12f69d-ead8-45af-8754-25fe06b01831",
   "metadata": {},
   "source": [
    "# Fix Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a1a0a8-baa0-49f6-9a88-d3e0ecf62203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffcddf1-a0e5-4d15-b560-fe38f975b65a",
   "metadata": {},
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acebfec3-31f1-4a41-ac9e-139c9fd4aff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet(num_classes=CFG['n_cls'])\n",
    "model.load_state_dict(torch.load(\"./checkpoints/fine_tuned_conv_net.pth\", map_location=\"cpu\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc17ce-6665-414b-850f-f7086a85028b",
   "metadata": {},
   "source": [
    "# ONNX 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887ccdc5-23ac-490b-bfab-a9d62ce991a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_h, img_w = CFG['imgsz']\n",
    "dummy_input = torch.randn(1, 3, img_h, img_w)\n",
    "\n",
    "torch.onnx.export(model,\n",
    "                  dummy_input,\n",
    "                  \"./checkpoints/conv_net.onnx\",\n",
    "                  input_names=['input'],\n",
    "                  output_names=['output'],\n",
    "                  dynamic_axes={'input': {0: 'batch_size'}})  # 0번째 차원 dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1072e5-9f26-4732-8095-7fc77e89e7a2",
   "metadata": {},
   "source": [
    "# INT8 양자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45315bd0-a3fe-4758-aa65-d8af6f2fcb45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageFolderDataReader(CalibrationDataReader):\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "        self.iterator = iter(self.dataloader)\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            inputs, _ = next(self.iterator)\n",
    "            return {\"input\": inputs.numpy()}\n",
    "        \n",
    "        except StopIteration:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "868b7502-2ff8-4744-9f9b-b5102f8e261c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "WARNING:root:Please consider pre-processing before quantization. See https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(CFG['imgsz']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=CFG['mean'], std=CFG['std'])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(\"./data/train/\", transform=transform)  # 전체 데이터\n",
    "calibration_loader = DataLoader(dataset, batch_size=CFG['bs'], shuffle=False)\n",
    "data_reader = ImageFolderDataReader(calibration_loader)\n",
    "\n",
    "quantize_static(model_input=\"./checkpoints/conv_net.onnx\",\n",
    "                model_output=\"./checkpoints/conv_net_int8.onnx\",\n",
    "                calibration_data_reader=data_reader,  # calibration data로 전체 데이터 사용\n",
    "                quant_format=QuantFormat.QDQ,\n",
    "                weight_type=QuantType.QInt8,\n",
    "                activation_type=QuantType.QInt8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bcea2d-1291-4f79-b3fb-2450e41051a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "real",
   "language": "python",
   "name": "real"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
